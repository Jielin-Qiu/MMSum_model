{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beec16f1-2b6e-4306-9c41-18ff4558cb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Frame encoder\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import efficientnet_b5\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3720fc9d-37da-4ea1-a9c1-b20f5c06f5f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34fdbf5d-d1e6-439b-b5d2-4902aa36370e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downlaod a sample image from the COCO dataset\n",
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "img = cv2.imread(\"input.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d746a62-69ba-4799-a79a-3cf3f8a27f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674e7d02781149789b12572cce6d2008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8386fac0c14212b3f9517d33450cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe116bd9ab14af4bf5500577ae14e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b5_lukemelas-b6417697.pth\" to /home/william/.cache/torch/hub/checkpoints/efficientnet_b5_lukemelas-b6417697.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea25db41f0046429bd980b146bcd972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load feature extractors\n",
    "feature_extractor_VIT = ViTFeatureExtractor.from_pretrained('google/vit-base-patch32-224-in21k')\n",
    "model_vit = ViTModel.from_pretrained('google/vit-base-patch32-224-in21k').to(device)\n",
    "model_vit.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(456, InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(456),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "model_effnet = efficientnet_b5(pretrained=True).to(device)\n",
    "model_effnet.eval()\n",
    "return_nodes = {\"flatten\": \"flatten\"}\n",
    "feature_extractor_EFF = create_feature_extractor(model_effnet, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d17b152b-e976-4894-b297-182ba145a0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features from ViT model\n",
    "inputs = feature_extractor_VIT(images=[img], return_tensors=\"pt\")\n",
    "outputs = model_vit(**inputs.to(device))\n",
    "last_hidden_states = outputs.pooler_output\n",
    "_VIT = last_hidden_states.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d296c01-928a-45f1-8928-f9cb4b951e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features from EfficientNet model\n",
    "res = feature_extractor_EFF(preprocess(img).to(device)[None, :, :, :])[\"flatten\"]\n",
    "_EFF = res.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6c4c00-920c-48c0-a4b9-e71d5eb30ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the expected feature shape\n",
    "assert _EFF.shape == (1, 2048)\n",
    "assert _VIT.shape == (1, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2900f4-8578-4650-b7f6-7b5e2c4bc7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the downlaoded file\n",
    "! rm input.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
