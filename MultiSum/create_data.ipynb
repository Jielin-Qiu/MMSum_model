{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import open_file\n",
    "import glob\n",
    "list_of_annotations = glob.glob('../../../jielin/msmo/annotation/*/*/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = []\n",
    "train_date = []\n",
    "train_headline = []\n",
    "train_article = []\n",
    "train_abstract = []\n",
    "\n",
    "dev_id = []\n",
    "dev_date = []\n",
    "dev_headline = []\n",
    "dev_article = []\n",
    "dev_abstract = []\n",
    "\n",
    "test_id = []\n",
    "test_date = []\n",
    "test_headline = []\n",
    "test_article = []\n",
    "test_abstract = []\n",
    "\n",
    "\n",
    "for idx in range(len(list_of_annotations)):\n",
    "    instance = open_file(list_of_annotations[idx])\n",
    "    key = instance['info']['video_id']\n",
    "    title = instance['info']['title']\n",
    "    \n",
    "    if key[-4:] == '0021' or key[-4:] == '0022' or key[-4:] == '0023' \\\n",
    "        or key[-4:] == '0024' or key[-4:] == '0025':\n",
    "            \n",
    "        test_headline.append(title)\n",
    "        test_id.append(key)\n",
    "        test_date.append(0)\n",
    "        test_article.append(clean_text(' '.join([item['summary'] for item in instance['transcript']])))\n",
    "        test_abstract.append(clean_text(' '.join([item['summary'] for item in instance['summary']])))\n",
    "        \n",
    "    elif key[-4:] == '0026' or key[-4:] == '0027' or key[-4:] == '0028' \\\n",
    "        or key[-4:] == '0029':\n",
    "        \n",
    "        dev_headline.append(title)\n",
    "        dev_id.append(key)\n",
    "        dev_date.append(0)\n",
    "        dev_article.append(clean_text(' '.join([item['summary'] for item in instance['transcript']])))\n",
    "        dev_abstract.append(clean_text(' '.join([item['summary'] for item in instance['summary']])))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        train_headline.append(title)\n",
    "        train_id.append(key)\n",
    "        train_date.append(0)\n",
    "        train_article.append(clean_text(' '.join([item['summary'] for item in instance['transcript']])))\n",
    "        train_abstract.append(clean_text(' '.join([item['summary'] for item in instance['summary']])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "column_names = [\"id\", \"date\", \"headline\", \"article\", \"abstract\"]\n",
    "\n",
    "# Open the file in write mode\n",
    "with open('src/data/train_mms_joined.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(train_id, train_date, train_headline, train_article, train_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)\n",
    "        \n",
    "# Open the file in write mode\n",
    "with open('src/data/test_mms_joined.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(test_id, test_date, test_headline, test_article, test_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)\n",
    "        \n",
    "# Open the file in write mode\n",
    "with open('src/data/dev_mms_joined.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(dev_id, dev_date, dev_headline, dev_article, dev_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_to_seconds(time_string):\n",
    "    hours, minutes, seconds = map(int, time_string.split(\":\"))\n",
    "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_summaries_by_time(start_time, end_time, summaries):\n",
    "    joined_summary = []\n",
    "    for summary in summaries:\n",
    "        if start_time <= time_to_seconds(summary['start_time']) <= end_time and start_time <= time_to_seconds(summary['end_time']) <= end_time:\n",
    "            joined_summary.append(summary['summary'])\n",
    "    return ' '.join(joined_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = []\n",
    "train_date = []\n",
    "train_headline = []\n",
    "train_article = []\n",
    "train_abstract = []\n",
    "\n",
    "dev_id = []\n",
    "dev_date = []\n",
    "dev_headline = []\n",
    "dev_article = []\n",
    "dev_abstract = []\n",
    "\n",
    "test_id = []\n",
    "test_date = []\n",
    "test_headline = []\n",
    "test_article = []\n",
    "test_abstract = []\n",
    "\n",
    "count_0 = 0\n",
    "for idx in range(len(list_of_annotations)):\n",
    "    instance = open_file(list_of_annotations[idx])\n",
    "    key = instance['info']['video_id']\n",
    "    title = instance['info']['title']\n",
    "    segments = instance['summary']\n",
    "    transcripts = instance['transcript']\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for seg in segments:\n",
    "        start_time = time_to_seconds(seg['start_time'])\n",
    "        end_time = time_to_seconds(seg['end_time'])\n",
    "                    \n",
    "        seg_summary = join_summaries_by_time(start_time, end_time, transcripts)\n",
    "    \n",
    "        if key[-4:] == '0021' or key[-4:] == '0022' or key[-4:] == '0023' \\\n",
    "            or key[-4:] == '0024' or key[-4:] == '0025':\n",
    "                \n",
    "            test_headline.append(title)\n",
    "            test_id.append(f'{key}_{count}')\n",
    "            test_date.append(0)\n",
    "            test_article.append(clean_text(seg_summary))\n",
    "            test_abstract.append(clean_text(seg['summary']))\n",
    "            \n",
    "        elif key[-4:] == '0026' or key[-4:] == '0027' or key[-4:] == '0028' \\\n",
    "            or key[-4:] == '0029':\n",
    "            \n",
    "            dev_headline.append(title)\n",
    "            dev_id.append(f'{key}_{count}')\n",
    "            dev_date.append(0)\n",
    "            dev_article.append(clean_text(seg_summary))\n",
    "            dev_abstract.append(clean_text(seg['summary']))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_headline.append(title)\n",
    "            train_id.append(f'{key}_{count}')\n",
    "            train_date.append(0)\n",
    "            train_article.append(clean_text(seg_summary))\n",
    "            train_abstract.append(clean_text(seg['summary']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "column_names = [\"id\", \"date\", \"headline\", \"article\", \"abstract\"]\n",
    "\n",
    "# Open the file in write mode\n",
    "with open('src/data/train_mms_joined_2.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(train_id, train_date, train_headline, train_article, train_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)\n",
    "        \n",
    "# Open the file in write mode\n",
    "with open('src/data/test_mms_joined_2.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(test_id, test_date, test_headline, test_article, test_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)\n",
    "        \n",
    "# Open the file in write mode\n",
    "with open('src/data/dev_mms_joined_2.tsv', 'w') as tsv_file:\n",
    "    # Write the header line\n",
    "    header = '\\t'.join(column_names) + '\\n'\n",
    "    tsv_file.write(header)\n",
    "    \n",
    "    # Iterate over the lists simultaneously using zip\n",
    "    for item1, item2, item3, item4, item5 in zip(dev_id, dev_date, dev_headline, dev_article, dev_abstract):\n",
    "        # Write the values separated by tabs\n",
    "        row = f\"{item1}\\t{item2}\\t{item3}\\t{item4}\\t{item5}\\n\"\n",
    "        tsv_file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "thumbnail = 'src/data/thumbnails/'\n",
    "keyframe = 'src/data/keyframes/'\n",
    "video = 'src/data/videos/'\n",
    "\n",
    "for i in sorted(os.listdir(thumbnail)):\n",
    "    thumb_arr = np.load(os.path.join(thumbnail, i))\n",
    "    key_arr = np.load(os.path.join(keyframe, i))\n",
    "    video_arr = np.load(os.path.join(video, i))\n",
    "    count = 0\n",
    "    for j in range(key_arr.shape[0]):\n",
    "        # np.save(f\"src/data/thumbnails2/{i.split('.')[0]}_{count}.npy\", thumb_arr)\n",
    "        np.save(f\"src/data/keyframes2/{i.split('.')[0]}_{count}.npy\", key_arr[j].reshape((1, key_arr[j].shape[0])))\n",
    "        # np.save(f\"src/data/videos2/{i.split('.')[0]}_{count}.npy\", video_arr)\n",
    "    \n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "df = pd.read_csv(\n",
    "    'src/data/train_mms_joined_2.tsv',\n",
    "    sep=\"\\t\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COOPOA0009_0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Make Perfect POACHED EGGS - Cooking Basics</td>\n",
       "      <td>Hey everyone Its Natasha of NatashasKitchenco...</td>\n",
       "      <td>Intro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOPOA0009_0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Make Perfect POACHED EGGS - Cooking Basics</td>\n",
       "      <td>you can poach one to four eggs at a time If yo...</td>\n",
       "      <td>What pot to use for poached eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COOPOA0009_0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Make Perfect POACHED EGGS - Cooking Basics</td>\n",
       "      <td>Im using large cold eggs right out of the refr...</td>\n",
       "      <td>Type of eggs to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COOPOA0009_0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Make Perfect POACHED EGGS - Cooking Basics</td>\n",
       "      <td>before transferring it to the ramekin so you c...</td>\n",
       "      <td>Egg cracking tip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COOPOA0009_0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Make Perfect POACHED EGGS - Cooking Basics</td>\n",
       "      <td>Once you have all of your eggs cracked into in...</td>\n",
       "      <td>Preparing the water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27486</th>\n",
       "      <td>SPOFOO0005_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Crest: An Inside Look At USMNT Matc...</td>\n",
       "      <td>were about to do a broadcast walkthrough with ...</td>\n",
       "      <td>Broadcast Walkthrough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27487</th>\n",
       "      <td>SPOFOO0005_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Crest: An Inside Look At USMNT Matc...</td>\n",
       "      <td>next up so item 44 similar to what we did in i...</td>\n",
       "      <td>PreGame Light Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27488</th>\n",
       "      <td>SPOFOO0005_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Crest: An Inside Look At USMNT Matc...</td>\n",
       "      <td>for world cup qualifiers theres a theres a big...</td>\n",
       "      <td>Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27489</th>\n",
       "      <td>SPOFOO0005_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Crest: An Inside Look At USMNT Matc...</td>\n",
       "      <td>a production in orlando is not going to be the...</td>\n",
       "      <td>Walkouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27490</th>\n",
       "      <td>SPOFOO0005_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Crest: An Inside Look At USMNT Matc...</td>\n",
       "      <td>much right teams and referees should be leavin...</td>\n",
       "      <td>FIFA Anthem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26692 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  date                                           headline  \\\n",
       "0      COOPOA0009_0     0  How to Make Perfect POACHED EGGS - Cooking Basics   \n",
       "1      COOPOA0009_0     0  How to Make Perfect POACHED EGGS - Cooking Basics   \n",
       "2      COOPOA0009_0     0  How to Make Perfect POACHED EGGS - Cooking Basics   \n",
       "3      COOPOA0009_0     0  How to Make Perfect POACHED EGGS - Cooking Basics   \n",
       "4      COOPOA0009_0     0  How to Make Perfect POACHED EGGS - Cooking Basics   \n",
       "...             ...   ...                                                ...   \n",
       "27486  SPOFOO0005_0     0  Behind The Crest: An Inside Look At USMNT Matc...   \n",
       "27487  SPOFOO0005_0     0  Behind The Crest: An Inside Look At USMNT Matc...   \n",
       "27488  SPOFOO0005_0     0  Behind The Crest: An Inside Look At USMNT Matc...   \n",
       "27489  SPOFOO0005_0     0  Behind The Crest: An Inside Look At USMNT Matc...   \n",
       "27490  SPOFOO0005_0     0  Behind The Crest: An Inside Look At USMNT Matc...   \n",
       "\n",
       "                                                 article  \\\n",
       "0       Hey everyone Its Natasha of NatashasKitchenco...   \n",
       "1      you can poach one to four eggs at a time If yo...   \n",
       "2      Im using large cold eggs right out of the refr...   \n",
       "3      before transferring it to the ramekin so you c...   \n",
       "4      Once you have all of your eggs cracked into in...   \n",
       "...                                                  ...   \n",
       "27486  were about to do a broadcast walkthrough with ...   \n",
       "27487  next up so item 44 similar to what we did in i...   \n",
       "27488  for world cup qualifiers theres a theres a big...   \n",
       "27489  a production in orlando is not going to be the...   \n",
       "27490  much right teams and referees should be leavin...   \n",
       "\n",
       "                               abstract  \n",
       "0                                 Intro  \n",
       "1      What pot to use for poached eggs  \n",
       "2                   Type of eggs to use  \n",
       "3                      Egg cracking tip  \n",
       "4                   Preparing the water  \n",
       "...                                 ...  \n",
       "27486             Broadcast Walkthrough  \n",
       "27487                PreGame Light Show  \n",
       "27488                          Security  \n",
       "27489                          Walkouts  \n",
       "27490                       FIFA Anthem  \n",
       "\n",
       "[26692 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('src/data/train_mms_joined_2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i in df.article:\n",
    "    if i == 'nan':\n",
    "        print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_delete = 'Simple, Easy & it was DELICIOUS!'\n",
    "df = df.drop(df[df['id'] == value_to_delete].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('src/data/test_mms_2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "   if df.iloc[i, :][0] == 'Simple, Easy & it was DELICIOUS!':\n",
    "       print('hello')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           Simple, Easy & it was DELICIOUS!\n",
      "date        [\"hi everyone today I'm going to do my\", 'simp...\n",
      "headline                                                Intro\n",
      "article                                                   NaN\n",
      "abstract                                                  NaN\n",
      "Name: 73, dtype: object\n",
      "id                           Simple, Easy & it was DELICIOUS!\n",
      "date        ['first I am going to add a couple of', 'table...\n",
      "headline                                              Cooking\n",
      "article                                                   NaN\n",
      "abstract                                                  NaN\n",
      "Name: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "   if df.iloc[i, :][0] == 'Simple, Easy & it was DELICIOUS!':\n",
    "       print(df.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
